# üë§ √âtape 2 ‚Äî L'Identification Visuelle (InsightFace)

## üìã Summary (√Ä lire AVANT de commencer)

**Objectif** : Impl√©menter la reconnaissance faciale avec **InsightFace** pour identifier les personnes d√©tect√©es via une **liste blanche**. Chaque personne se verra attribuer un nom ("Thomas", "Sarah") ou le label "INCONNU".

**Dur√©e estim√©e** : 2-3 heures

**Pr√©requis** :
- ‚úÖ √âtape 0 ET √âtape 1 enti√®rement valid√©es
- ‚úÖ Le d√©tecteur YOLOv8-Pose fonctionne avec les bo√Ætes englobantes
- ‚úÖ Au moins 2-3 photos de visages pour la liste blanche (photos claires, de face)

**Ce que vous aurez √† la fin** :
- ‚úÖ Module d'encodage des visages de r√©f√©rence (whitelist)
- ‚úÖ Module de reconnaissance faciale en temps r√©el
- ‚úÖ Strat√©gie "paresseuse" : scan uniquement quand n√©cessaire
- ‚úÖ Labels "Thomas" ou "INCONNU" affich√©s sur la vid√©o
- ‚úÖ Test complet avec identification en temps r√©el

---

## üìù √âtapes D√©taill√©es

### 2.1 ‚Äî Pr√©parer les Photos de la Liste Blanche

> [!IMPORTANT]
> La qualit√© des photos de r√©f√©rence d√©termine directement la fiabilit√© de la reconnaissance. Utilisez des photos claires, bien √©clair√©es, de face, sans lunettes de soleil.

**Actions :**

1. Placer les photos dans `data/whitelist_photos/` avec le format de nommage :
   ```
   data/whitelist_photos/
   ‚îú‚îÄ‚îÄ thomas_1.jpg
   ‚îú‚îÄ‚îÄ thomas_2.jpg     ‚Üê Plusieurs photos par personne = meilleure pr√©cision
   ‚îú‚îÄ‚îÄ sarah_1.jpg
   ‚îú‚îÄ‚îÄ sarah_2.jpg
   ‚îî‚îÄ‚îÄ admin_1.jpg
   ```

2. **Convention de nommage** : `{prenom}_{numero}.jpg`
   - Le pr√©nom (avant le `_`) sera utilis√© comme label d'identification
   - Fournir 2-5 photos par personne (angles l√©g√®rement diff√©rents)

**‚úÖ Crit√®re de validation 2.1** :
```powershell
dir data\whitelist_photos\
# DOIT contenir au moins 1 photo par personne √† identifier
# Format : prenom_numero.jpg
```

---

### 2.2 ‚Äî Cr√©er le Module d'Encodage (`src/face_recognition/encoder.py`)

**Actions :**

Cr√©er `src/face_recognition/encoder.py` :

```python
"""
Module d'encodage des visages.
Convertit les photos de r√©f√©rence en vecteurs d'embedding (fichiers .npy).
Utilise InsightFace (ArcFace) pour l'extraction des features.
"""
import os
import sys
import numpy as np
import cv2
from pathlib import Path
from typing import Dict, List, Tuple
import insightface
from insightface.app import FaceAnalysis

sys.path.append(str(Path(__file__).parent.parent.parent))
from src.config import WHITELIST_DIR, FACE_RECOGNITION_THRESHOLD


class FaceEncoder:
    """
    Encode les visages de r√©f√©rence en vecteurs d'embedding.
    """

    def __init__(self, det_size: tuple = (640, 640)):
        """
        Initialise InsightFace.
        
        Args:
            det_size: Taille de d√©tection (plus grand = plus pr√©cis mais plus lent)
        """
        print("[ENCODER] Initialisation d'InsightFace...")
        self.app = FaceAnalysis(
            name="buffalo_l",  # Mod√®le de haute qualit√©
            providers=["CUDAExecutionProvider", "CPUExecutionProvider"]
        )
        self.app.prepare(ctx_id=0, det_size=det_size)
        print("[ENCODER] InsightFace pr√™t.")

    def encode_photo(self, image_path: str) -> np.ndarray:
        """
        Encode une photo en vecteur d'embedding.
        
        Args:
            image_path: Chemin vers la photo
            
        Returns:
            Vecteur d'embedding (512,) ou None si aucun visage d√©tect√©
        """
        img = cv2.imread(str(image_path))
        if img is None:
            print(f"  ‚ö† Impossible de lire : {image_path}")
            return None

        faces = self.app.get(img)
        if len(faces) == 0:
            print(f"  ‚ö† Aucun visage d√©tect√© dans : {image_path}")
            return None

        if len(faces) > 1:
            print(f"  ‚ö† {len(faces)} visages d√©tect√©s dans {image_path}, "
                  f"utilisation du plus grand")
            # Prendre le visage avec la plus grande bo√Æte
            faces = sorted(faces, key=lambda f: 
                          (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]),
                          reverse=True)

        embedding = faces[0].embedding  # Vecteur (512,)
        # Normaliser le vecteur
        embedding = embedding / np.linalg.norm(embedding)
        return embedding

    def build_whitelist(self, photos_dir: str = None) -> Dict[str, np.ndarray]:
        """
        Construit la liste blanche en encodant toutes les photos de r√©f√©rence.
        
        Convention : les fichiers sont nomm√©s {prenom}_{numero}.jpg
        Moyenne des embeddings par personne pour plus de robustesse.
        
        Args:
            photos_dir: Dossier contenant les photos (d√©faut: config.WHITELIST_DIR)
            
        Returns:
            Dict {nom: embedding_moyen (512,)}
        """
        if photos_dir is None:
            photos_dir = WHITELIST_DIR

        photos_dir = Path(photos_dir)
        if not photos_dir.exists():
            print(f"‚ùå Dossier introuvable : {photos_dir}")
            return {}

        print(f"\n[ENCODER] Construction de la liste blanche depuis : {photos_dir}")
        print("=" * 50)

        # Regrouper les photos par nom
        name_embeddings: Dict[str, List[np.ndarray]] = {}
        
        for photo_path in sorted(photos_dir.glob("*.jpg")):
            # Extraire le nom depuis le fichier (ex: "thomas_1.jpg" ‚Üí "thomas")
            name = photo_path.stem.rsplit("_", 1)[0].capitalize()
            
            print(f"  Encodage : {photo_path.name} ‚Üí {name}...", end=" ")
            embedding = self.encode_photo(photo_path)
            
            if embedding is not None:
                if name not in name_embeddings:
                    name_embeddings[name] = []
                name_embeddings[name].append(embedding)
                print("‚úÖ")
            else:
                print("‚ùå")

        # Calculer la moyenne des embeddings par personne
        whitelist: Dict[str, np.ndarray] = {}
        for name, embeddings in name_embeddings.items():
            mean_emb = np.mean(embeddings, axis=0)
            mean_emb = mean_emb / np.linalg.norm(mean_emb)  # Re-normaliser
            whitelist[name] = mean_emb
            print(f"  ‚Üí {name} : {len(embeddings)} photo(s) encod√©e(s)")

        print(f"\n[ENCODER] Liste blanche : {len(whitelist)} personne(s)")
        return whitelist

    def save_whitelist(self, whitelist: Dict[str, np.ndarray], 
                       output_dir: str = None):
        """
        Sauvegarde la liste blanche en fichiers .npy.
        
        Args:
            whitelist: Dict {nom: embedding}
            output_dir: Dossier de sortie (d√©faut: src/face_recognition/whitelist/)
        """
        if output_dir is None:
            output_dir = Path(__file__).parent / "whitelist"
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        for name, embedding in whitelist.items():
            path = output_dir / f"{name.lower()}.npy"
            np.save(path, embedding)
            print(f"  Sauvegard√© : {path}")

        # Sauvegarder aussi la liste des noms
        names_path = output_dir / "names.npy"
        np.save(names_path, list(whitelist.keys()))
        print(f"  Liste des noms : {names_path}")

    def load_whitelist(self, whitelist_dir: str = None) -> Dict[str, np.ndarray]:
        """
        Charge la liste blanche depuis les fichiers .npy.
        
        Returns:
            Dict {nom: embedding}
        """
        if whitelist_dir is None:
            whitelist_dir = Path(__file__).parent / "whitelist"
        
        whitelist_dir = Path(whitelist_dir)
        if not whitelist_dir.exists():
            print(f"‚ö† Dossier whitelist introuvable : {whitelist_dir}")
            return {}

        whitelist = {}
        names_path = whitelist_dir / "names.npy"
        
        if names_path.exists():
            names = np.load(names_path, allow_pickle=True)
            for name in names:
                emb_path = whitelist_dir / f"{name.lower()}.npy"
                if emb_path.exists():
                    whitelist[name] = np.load(emb_path)
                    
        print(f"[ENCODER] Whitelist charg√©e : {len(whitelist)} personne(s)")
        return whitelist
```

**‚úÖ Crit√®re de validation 2.2** :
```python
python -c "
from src.face_recognition.encoder import FaceEncoder
encoder = FaceEncoder()
print('‚úÖ FaceEncoder initialis√© avec succ√®s')

# Construire et sauvegarder la whitelist
whitelist = encoder.build_whitelist()
if whitelist:
    encoder.save_whitelist(whitelist)
    print(f'‚úÖ Whitelist cr√©√©e : {len(whitelist)} personne(s)')
    
    # Recharger pour v√©rifier
    loaded = encoder.load_whitelist()
    assert len(loaded) == len(whitelist), 'Erreur de rechargement !'
    print('‚úÖ Whitelist recharg√©e avec succ√®s')
else:
    print('‚ö† Aucune photo trouv√©e dans data/whitelist_photos/')
"
```

---

### 2.3 ‚Äî Cr√©er le Module de Matching (`src/face_recognition/matcher.py`)

**Actions :**

Cr√©er `src/face_recognition/matcher.py` :

```python
"""
Module de comparaison des visages.
Compare un visage d√©tect√© aux embeddings de la liste blanche.
Int√®gre la strat√©gie "paresseuse" pour √©conomiser le GPU.
"""
import numpy as np
import cv2
import time
from typing import Optional, Dict, Tuple
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent.parent.parent))
from src.config import (
    FACE_RECOGNITION_THRESHOLD, 
    FACE_RECOGNITION_INTERVAL,
    FACE_CONFIDENCE_LOCK
)
from src.face_recognition.encoder import FaceEncoder


class FaceMatcher:
    """
    G√®re la reconnaissance faciale avec strat√©gie paresseuse.
    
    Strat√©gie :
    1. Ne scanner que les INCONNUS
    2. Scanner 1 fois toutes les FACE_RECOGNITION_INTERVAL frames
    3. Arr√™ter de scanner une fois identifi√© avec ‚â• FACE_CONFIDENCE_LOCK
    """

    def __init__(self):
        """Initialise le matcher."""
        self.encoder = FaceEncoder()
        self.whitelist: Dict[str, np.ndarray] = {}
        self._identified: Dict[int, Tuple[str, float]] = {}  # {track_id: (nom, score)}
        self._last_scan: Dict[int, int] = {}  # {track_id: dernier frame scann√©}

    def load_whitelist(self):
        """Charge la liste blanche depuis les fichiers .npy."""
        self.whitelist = self.encoder.load_whitelist()
        if not self.whitelist:
            print("‚ö† [MATCHER] Liste blanche vide ! Lancer d'abord l'encodage.")

    def should_scan(self, track_id: int, frame_count: int) -> bool:
        """
        D√©termine si on doit scanner le visage de cette personne.
        
        R√®gles :
        - Si d√©j√† identifi√© avec haute confiance ‚Üí NON
        - Si scann√© trop r√©cemment ‚Üí NON
        - Sinon ‚Üí OUI
        """
        # D√©j√† identifi√© avec certitude ?
        if track_id in self._identified:
            _, score = self._identified[track_id]
            if score >= FACE_CONFIDENCE_LOCK:
                return False

        # Scann√© trop r√©cemment ?
        if track_id in self._last_scan:
            if (frame_count - self._last_scan[track_id]) < FACE_RECOGNITION_INTERVAL:
                return False

        return True

    def identify(self, face_crop: np.ndarray, track_id: int, 
                 frame_count: int) -> Tuple[str, float]:
        """
        Identifie un visage par comparaison avec la liste blanche.
        
        Args:
            face_crop: Image recadr√©e du visage (BGR)
            track_id: ID de suivi de la personne
            frame_count: Num√©ro de frame actuel
            
        Returns:
            (nom, score) : ("Thomas", 0.87) ou ("INCONNU", 0.0)
        """
        # V√©rifier si on doit scanner
        if not self.should_scan(track_id, frame_count):
            if track_id in self._identified:
                return self._identified[track_id]
            return ("INCONNU", 0.0)

        # Marquer le scan
        self._last_scan[track_id] = frame_count

        # D√©tecter le visage dans le crop
        faces = self.encoder.app.get(face_crop)
        if len(faces) == 0:
            if track_id in self._identified:
                return self._identified[track_id]
            return ("INCONNU", 0.0)

        # Prendre le visage principal
        query_emb = faces[0].embedding
        query_emb = query_emb / np.linalg.norm(query_emb)

        # Comparer avec la whitelist
        best_name = "INCONNU"
        best_score = 0.0

        for name, ref_emb in self.whitelist.items():
            # Similarit√© cosinus
            score = float(np.dot(query_emb, ref_emb))
            if score > best_score:
                best_score = score
                best_name = name

        # Seuil de reconnaissance
        if best_score < FACE_RECOGNITION_THRESHOLD:
            result = ("INCONNU", best_score)
        else:
            result = (best_name, best_score)
            self._identified[track_id] = result
            print(f"  üîç ID:{track_id} identifi√© comme {best_name} "
                  f"(score: {best_score:.3f})")

        return result

    def get_name(self, track_id: int) -> str:
        """Retourne le nom connu d'un track_id, ou 'INCONNU'."""
        if track_id in self._identified:
            return self._identified[track_id][0]
        return "INCONNU"

    def cleanup_lost_ids(self, active_ids: set):
        """Nettoie les IDs qui ne sont plus suivis."""
        lost_ids = set(self._identified.keys()) - active_ids
        for lost_id in lost_ids:
            del self._identified[lost_id]
            if lost_id in self._last_scan:
                del self._last_scan[lost_id]

    def get_stats(self) -> dict:
        """Retourne les statistiques du matcher."""
        return {
            "whitelist_size": len(self.whitelist),
            "identified_count": len(self._identified),
            "identified_persons": {
                tid: (name, f"{score:.3f}") 
                for tid, (name, score) in self._identified.items()
            }
        }
```

**‚úÖ Crit√®re de validation 2.3** :
```python
python -c "
from src.face_recognition.matcher import FaceMatcher
matcher = FaceMatcher()
matcher.load_whitelist()
stats = matcher.get_stats()
print(f'‚úÖ FaceMatcher initialis√©')
print(f'  Whitelist : {stats[\"whitelist_size\"]} personne(s)')
print(f'  Identifi√©es : {stats[\"identified_count\"]}')
"
```

---

### 2.4 ‚Äî Int√©grer InsightFace dans le Pipeline de D√©tection

**Actions :**

Modifier le test pour inclure la reconnaissance faciale :

Cr√©er `tests/test_face_recognition.py` :

```python
"""
Test complet de la reconnaissance faciale int√©gr√©e au d√©tecteur.
"""
import cv2
import time
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))
from src.pipeline.detector import PoseDetector
from src.face_recognition.matcher import FaceMatcher
from src.utils.drawing import draw_detections, draw_fps


def test_face_recognition(source=0):
    """Test la reconnaissance faciale en temps r√©el."""
    
    print("[TEST] Initialisation...")
    detector = PoseDetector()
    matcher = FaceMatcher()
    matcher.load_whitelist()
    
    cap = cv2.VideoCapture(source)
    if not cap.isOpened():
        print(f"‚ùå Impossible d'ouvrir : {source}")
        return False
    
    fps_counter = 0
    fps_start = time.time()
    current_fps = 0.0
    
    print("[TEST] D√©marrage (Appuyez sur 'q' pour quitter)")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            if isinstance(source, str):
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue
            break
        
        # D√©tection
        detections = detector.detect(frame)
        
        # Reconnaissance faciale
        for det in detections:
            if matcher.should_scan(det.track_id, detector.frame_count):
                # Extraire la zone de la t√™te (tiers sup√©rieur de la bbox)
                head = det.head_bbox.astype(int)
                x1, y1, x2, y2 = head
                # S√©curiser les bornes
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(frame.shape[1], x2)
                y2 = min(frame.shape[0], y2)
                
                if x2 > x1 and y2 > y1:
                    face_crop = frame[y1:y2, x1:x2]
                    name, score = matcher.identify(
                        face_crop, det.track_id, detector.frame_count
                    )
                    det.name = name
            else:
                det.name = matcher.get_name(det.track_id)
        
        # Nettoyer les IDs perdus
        active_ids = {d.track_id for d in detections}
        matcher.cleanup_lost_ids(active_ids)
        
        # Affichage
        annotated = draw_detections(frame, detections)
        annotated = draw_fps(annotated, current_fps)
        
        # FPS
        fps_counter += 1
        elapsed = time.time() - fps_start
        if elapsed >= 1.0:
            current_fps = fps_counter / elapsed
            fps_counter = 0
            fps_start = time.time()
        
        cv2.imshow("CCTV AI - Test Face Recognition", annotated)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
    
    stats = matcher.get_stats()
    print(f"\n[TEST] Statistiques reconnaissance faciale :")
    print(f"  Personnes identifi√©es : {stats['identified_persons']}")
    return True


if __name__ == "__main__":
    source = sys.argv[1] if len(sys.argv) > 1 else 0
    success = test_face_recognition(source)
    print(f"\n{'‚úÖ TEST R√âUSSI' if success else '‚ùå TEST √âCHOU√â'}")
```

**‚úÖ Crit√®re de validation 2.4** :
```powershell
python tests/test_face_recognition.py

# DOIT :
# - Afficher les bo√Ætes + squelettes (comme √©tape 1)
# - Afficher le nom (Thomas/Sarah) ou INCONNU sur chaque personne
# - Le nom doit rester stable apr√®s identification (pas de changements al√©atoires)
# - Le scan InsightFace ne doit pas tourner √† chaque frame
```

---

## ‚úÖ Checklist de Validation Finale ‚Äî √âtape 2

| # | Crit√®re | Commande/Action | Status |
|---|---------|-----------------|--------|
| 2.1 | Photos de r√©f√©rence pr√©par√©es | Placer photos dans `data/whitelist_photos/` | ‚è≥ |
| 2.2 | Whitelist encod√©e et sauvegard√©e (.npy) | Encoder SCRFD+ArcFace OK | ‚úÖ |
| 2.3 | FaceMatcher fonctionnel | Import + init + strat√©gie lazy OK | ‚úÖ |
| 2.4 | Reconnaissance en temps r√©el | Script `test_face_recognition.py` pr√™t | ‚úÖ |

**V√©rifications fonctionnelles obligatoires :**
- [ ] Les personnes connues (whitelist) sont correctement identifi√©es
- [ ] Les personnes inconnues affichent "INCONNU"
- [ ] Le scan InsightFace est "paresseux" (pas √† chaque frame)
- [ ] Une fois identifi√© avec ‚â• 95%, la personne garde son nom sans re-scan
- [ ] Le nom est stable (ne change pas entre les frames)

> [!WARNING]
> Si la reconnaissance est trop lente (< 15 FPS), augmenter `FACE_RECOGNITION_INTERVAL` dans `config.py` (ex: passer de 60 √† 90 frames).

---

**‚¨ÖÔ∏è √âtape pr√©c√©dente : [etape_1.md](etape_1.md)**
**‚û°Ô∏è √âtape suivante : [etape_3.md](etape_3.md) ‚Äî Historique et Temps (SQLite)**
